{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Rescaling, RandomFlip, RandomRotation, RandomZoom, RandomContrast\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import kerastuner as kt\n",
    "\n",
    "# Business Context:\n",
    "# This project aims to classify products as either \"Defective\" or \"Good.\"\n",
    "# Goal: Improve production quality by accurately detecting defective products,\n",
    "# which helps reduce waste, improve customer satisfaction, and lower operational costs.\n",
    "\n",
    "# Constants\n",
    "BATCH_SIZE = 16\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "K_FOLDS = 5\n",
    "\n",
    "# Load datasets\n",
    "dataset = image_dataset_from_directory(\n",
    "    'data',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# EDA: Explore the dataset\n",
    "def explore_dataset(dataset, dataset_name):\n",
    "    print(f\"\\n--- Exploring {dataset_name} Dataset ---\")\n",
    "    class_counts = Counter([label.numpy() for _, label in dataset.unbatch()])\n",
    "    print(f\"Class Distribution in {dataset_name} Dataset:\")\n",
    "    for cls, count in class_counts.items():\n",
    "        print(f\"Class {cls} ({'Defective' if cls == 0 else 'Good'}): {count} samples\")\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.barplot(x=list(class_counts.keys()), y=list(class_counts.values()), palette=\"viridis\")\n",
    "    plt.title(f\"{dataset_name} Dataset Class Distribution\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks([0, 1], ['Defective', 'Good'])\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for images, labels in dataset.take(1):\n",
    "        for i in range(9):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "            plt.title(f\"Class: {'Defective' if labels[i] == 0 else 'Good'}\")\n",
    "            plt.axis(\"off\")\n",
    "    plt.suptitle(f\"Sample Images from {dataset_name} Dataset\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "# Perform EDA on the dataset\n",
    "explore_dataset(dataset, \"Complete\")\n",
    "\n",
    "# Data augmentation and normalization\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomRotation(0.1),\n",
    "    RandomZoom(0.1),\n",
    "    RandomContrast(0.1)\n",
    "])\n",
    "\n",
    "def preprocess_image(image, label):\n",
    "    image = data_augmentation(image)\n",
    "    image = Rescaling(1./255)(image)\n",
    "    return image, label\n",
    "\n",
    "dataset = dataset.map(preprocess_image)\n",
    "\n",
    "# Prefetch for performance improvement\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "def model_builder(hp):\n",
    "    base_model = VGG16(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), include_top=False, weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Hyperparameter tuning for learning rate and optimizer\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-4, 1e-3, 1e-2])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='tuner_dir',\n",
    "                     project_name='product_classifier_tuning')\n",
    "\n",
    "# Extract images and labels from the dataset\n",
    "def get_images_and_labels(dataset):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image, label in dataset.unbatch():\n",
    "        images.append(image.numpy())\n",
    "        labels.append(label.numpy())\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "images, labels = get_images_and_labels(dataset)\n",
    "\n",
    "# Cross-validation with hyperparameter tuning\n",
    "kf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True)\n",
    "fold_no = 1\n",
    "accuracies, precisions, recalls, f1s = [], [], [], []\n",
    "\n",
    "for train_index, val_index in kf.split(images, labels):\n",
    "    print(f\"--- Fold {fold_no} ---\")\n",
    "    train_images, val_images = images[train_index], images[val_index]\n",
    "    train_labels, val_labels = labels[train_index], labels[val_index]\n",
    "    \n",
    "    train_data = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(BATCH_SIZE)\n",
    "    val_data = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).batch(BATCH_SIZE)\n",
    "\n",
    "    train_data = train_data.map(preprocess_image).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    val_data = val_data.map(preprocess_image).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    tuner.search(train_data, validation_data=val_data, epochs=10)\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    print(f\"Best hyperparameters for fold {fold_no}: Learning rate: {best_hps.get('learning_rate')}\")\n",
    "    \n",
    "    model = tuner.hypermodel.build(best_hps)\n",
    "    history = model.fit(train_data, validation_data=val_data, epochs=10)\n",
    "    model.save_weights(f'defectandgood_classifier_fold_{fold_no}.weights.h5')\n",
    "\n",
    "    # Evaluate the model\n",
    "    val_predictions = np.argmax(model.predict(val_data), axis=-1)\n",
    "    val_true = np.concatenate([y for x, y in val_data], axis=0)\n",
    "\n",
    "    accuracies.append(accuracy_score(val_true, val_predictions))\n",
    "    precisions.append(precision_score(val_true, val_predictions))\n",
    "    recalls.append(recall_score(val_true, val_predictions))\n",
    "    f1s.append(f1_score(val_true, val_predictions))\n",
    "\n",
    "    print(f\"Fold {fold_no} Accuracy: {accuracies[-1]}\")\n",
    "    print(f\"Fold {fold_no} Precision: {precisions[-1]}\")\n",
    "    print(f\"Fold {fold_no} Recall: {recalls[-1]}\")\n",
    "    print(f\"Fold {fold_no} F1 Score: {f1s[-1]}\")\n",
    "\n",
    "    fold_no += 1\n",
    "    \n",
    "    # Clear Keras session\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "# Calculate average metrics\n",
    "average_accuracy = np.mean(accuracies)\n",
    "average_precision = np.mean(precisions)\n",
    "average_recall = np.mean(recalls)\n",
    "average_f1 = np.mean(f1s)\n",
    "print(f\"\\nAverage Accuracy: {average_accuracy}\")\n",
    "print(f\"Average Precision: {average_precision}\")\n",
    "print(f\"Average Recall: {average_recall}\")\n",
    "print(f\"Average F1 Score: {average_f1}\")\n",
    "\n",
    "# Business Impact Analysis\n",
    "def business_impact_report():\n",
    "    print(\"\\n--- Business Impact Report ---\")\n",
    "    print(f\"Final Average Test Accuracy: {average_accuracy:.2f}\")\n",
    "    print(f\"Final Average Precision: {average_precision:.2f}\")\n",
    "    print(f\"Final Average Recall: {average_recall:.2f}\")\n",
    "    print(f\"Final Average F1 Score: {average_f1:.2f}\")\n",
    "    print(\"Projected Business Benefits:\")\n",
    "    print(f\" - Reduction in defective products by {average_accuracy * 100:.2f}%.\")\n",
    "    print(\" - Improved quality control.\")\n",
    "    print(\" - Enhanced customer satisfaction.\")\n",
    "    print(\" - Lower production costs due to reduced waste.\")\n",
    "\n",
    "# Generate the report\n",
    "business_impact_report()\n",
    "\n",
    "# Optional: Visualize training and validation performance for the last fold\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "plot_training_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
